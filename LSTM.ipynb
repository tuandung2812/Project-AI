{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1883f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slide giáo trình đầy đủ .\n",
      "nhiệt tình giảng dạy , g\n",
      "\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import inputs\n",
    "with open('sents.txt', encoding='utf-8', mode='r') as f:\n",
    " reviews = f.read()\n",
    "with open('sentiments.txt', encoding='utf-8', mode='r') as f:\n",
    " labels = f.read()\n",
    "print(reviews[:50])\n",
    "print()\n",
    "print(labels[:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7526e2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11426\n"
     ]
    }
   ],
   "source": [
    "#Data processing\n",
    "\n",
    "#1. Lowercase\n",
    "reviews = reviews.lower()\n",
    "\n",
    "#2. Punctuation removal and remove abnormal reviews\n",
    "from string import punctuation\n",
    "\n",
    "all_text = \"\".join([c for c in reviews if (c not in punctuation)])\n",
    "\n",
    "reviews_split = all_text.split(\"\\n\")\n",
    "weird_r = [r for r in reviews_split if r in {\"\", \" \", \"\\n\", \"\\t\"}]\n",
    "\n",
    "reviews_split = [review for review in reviews_split if review not in weird_r]\n",
    "\n",
    "print(len(weird_r))\n",
    "print(len(reviews_split))\n",
    "\n",
    "#3. Label processing\n",
    "\n",
    "#Process raw data\n",
    "labels = [label for label in labels if (label != '') and (label != \"\\n\")]\n",
    "labels = [int(l)-1 for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c0b71d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thầy', 2989), ('sinh viên', 2682), ('dạy', 2161), ('và', 2068), ('không', 2060), ('rất', 1961), ('nhiệt tình', 1825), ('cho', 1722), ('có', 1709), ('hiểu', 1626), ('nhiều', 1621), ('giảng viên', 1610), ('dễ', 1264), ('học', 1221), ('bài', 1142), ('cô', 1141), ('nên', 1073), ('được', 1024), ('hơn', 1014), ('với', 973)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tiếp thu nhiệt tình'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m reviews_int \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m reviews_split:\n\u001b[1;32m---> 25\u001b[0m     r \u001b[38;5;241m=\u001b[39m [vocab_to_int[w] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m word_tokenize(review)]\n\u001b[0;32m     26\u001b[0m     reviews_int\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(reviews_int[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m reviews_int \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m reviews_split:\n\u001b[1;32m---> 25\u001b[0m     r \u001b[38;5;241m=\u001b[39m [\u001b[43mvocab_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m word_tokenize(review)]\n\u001b[0;32m     26\u001b[0m     reviews_int\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(reviews_int[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tiếp thu nhiệt tình'"
     ]
    }
   ],
   "source": [
    "#Tokenize\n",
    "\n",
    "#1. Split to words\n",
    "from collections import Counter\n",
    "from underthesea import word_tokenize\n",
    "import sklearn.feature_extraction.text.TfidfVectorizer\n",
    " \n",
    "all_text2 = ' '.join(reviews_split)\n",
    "\n",
    "words = word_tokenize(all_text2)\n",
    "\n",
    "#Count numbers of words\n",
    "count_words = Counter(words)\n",
    "\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)\n",
    "\n",
    "print(sorted_words[:20])\n",
    "\n",
    "#2. Create vocabs\n",
    "vocab_to_int = {w:i+1 for i, (w, c) in enumerate(sorted_words)}\n",
    "\n",
    "\n",
    "#3. Word-to-int\n",
    "reviews_int = []\n",
    "for review in reviews_split:\n",
    "    r = [vocab_to_int[w] for w in word_tokenize(review)]\n",
    "    reviews_int.append(r)\n",
    "print(reviews_int[0:3])\n",
    "print(len(reviews_int))\n",
    "print(len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad4b46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    11426.000000\n",
       "mean        12.678803\n",
       "std          9.548335\n",
       "min          1.000000\n",
       "25%          7.000000\n",
       "50%         10.000000\n",
       "75%         16.000000\n",
       "max        147.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analyzing data\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "reviews_len = [len(x) for x in reviews_int]\n",
    "pd.Series(reviews_len).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c6a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate too short or too long reviews\n",
    "reviews_int = [reviews_int[i] for i, l in enumerate(reviews_len) if (l > 0)]\n",
    "labels = [labels[i] for i, l in enumerate(reviews_len) if (l > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87151150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  119   45   51  122   90]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0   13\n",
      "     8    2    3  180  275   24    5    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    99    6  122   90 1518   97  211   36]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   47  212   69  139  448  140  279   10   35\n",
      "   127   89  285  264   14   67    2    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    4    2    7   32   11\n",
      "    16    7   17  132  133  440   82   33]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    2    1  182\n",
      "   147   60   72   64   33  262  236  299  256  208  161   31    5    1\n",
      "   123  192  392  208  161   14    5    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   30  178 1263   21   84   70   30  178\n",
      "     6   88  179   35    6  121  594   85]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0   60  134    6   40\n",
      "   340    9  182  147   85  109  120  100]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   83   76   21    6   11\n",
      "    86  282  201   23  474   71   44  339  339  767  595  344    5    1\n",
      "    12   42  202   26   83   76   21    6]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   36   65  105   28  223   49   51\n",
      "   326   64  393  225  129  350   98  119]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def pad_features(reviews_int, seq_length):\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_int):\n",
    "        review_len = len(review)\n",
    "        if review_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length - review_len))\n",
    "            new = zeroes + review\n",
    "        elif review_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        features[i,:] = np.array(new)\n",
    "    return features\n",
    "\n",
    "seq_length = 50\n",
    "features = pad_features(reviews_int, seq_length)\n",
    "\n",
    "print(features[:10, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "296018dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e74df4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m test_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(test_y)\n\u001b[0;32m     11\u001b[0m test_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(test_y)\n\u001b[1;32m---> 13\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(valid_x), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(valid_y))\n\u001b[0;32m     15\u001b[0m test_data \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_x), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(test_y))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:365\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "#Generate DataLoaders and Batchings\n",
    "    \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "train_x = np.array(train_x)\n",
    "valid_y = np.array(valid_y)\n",
    "valid_x = np.array(valid_x)\n",
    "test_y = np.array(test_y)\n",
    "test_x = np.array(test_y)\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "209fd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define networks \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    \n",
    "    def __init__ (self, vocab_size, output_size, embedded_dim, hidden_dim, n_layers, drop_prob = 0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = drop_prob, batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (cuda.is_available()):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67408c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(2486, 40)\n",
      "  (lstm): LSTM(40, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Initialization\n",
    "\n",
    "vocab_size = len(vocab_to_int) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 40\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc43a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 43, 256), got [2, 50, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda(), labels\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     70\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\n\u001b[1;32m---> 71\u001b[0m output, val_h \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     74\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mSentimentLSTM.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     24\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     26\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m---> 27\u001b[0m lstm_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m lstm_out \u001b[38;5;241m=\u001b[39m lstm_out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n\u001b[0;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(lstm_out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    757\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    762\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:685\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    680\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    681\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    682\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    683\u001b[0m                        ):\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 685\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    688\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:226\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    224\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 43, 256), got [2, 50, 256]"
     ]
    }
   ],
   "source": [
    "import torch.cuda as cuda\n",
    "import torch\n",
    "\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 4 \n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "train_on_gpu = cuda.is_available()\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    inputs = inputs.type(torch.LongTensor)\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfdf8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
