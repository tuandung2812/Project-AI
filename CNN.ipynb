{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d5c08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (4.16.0.dev0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: requests in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in c:\\users\\dung\\appdata\\roaming\\python\\python38\\site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "077a2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "import time\n",
    "import transformers\n",
    "\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8087fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./Data/processed/train.csv\", sep = \"|\")\n",
    "val_df = pd.read_csv(\"./Data/processed/validation.csv\", sep = \"|\")\n",
    "test_df = pd.read_csv(\"./Data/processed/test.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bedaf2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slide giáo_trình đầy_đủ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhiệt_tình giảng_dạy gần_gũi với sinh_viên</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đi học đầy_đủ full điểm chuyên cần</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chưa áp_dụng công_nghệ_thông_tin và các thiết_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thầy giảng bài hay có nhiều bài_tập ví_dụ ngay...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11421</th>\n",
       "      <td>chỉ vì môn game mà em học hai lần mà không qua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11422</th>\n",
       "      <td>em cảm_ơn cô nhiều</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11423</th>\n",
       "      <td>giao bài_tập quá nhiều</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11424</th>\n",
       "      <td>giáo_viên dạy dễ hiểu nhiệt_tình</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11425</th>\n",
       "      <td>gói gọn doubledot hay tận_tình phù_hợp với mọi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  sentiments\n",
       "0                                slide giáo_trình đầy_đủ           2\n",
       "1             nhiệt_tình giảng_dạy gần_gũi với sinh_viên           2\n",
       "2                     đi học đầy_đủ full điểm chuyên cần           0\n",
       "3      chưa áp_dụng công_nghệ_thông_tin và các thiết_...           0\n",
       "4      thầy giảng bài hay có nhiều bài_tập ví_dụ ngay...           2\n",
       "...                                                  ...         ...\n",
       "11421  chỉ vì môn game mà em học hai lần mà không qua...           0\n",
       "11422                                 em cảm_ơn cô nhiều           2\n",
       "11423                             giao bài_tập quá nhiều           0\n",
       "11424                   giáo_viên dạy dễ hiểu nhiệt_tình           2\n",
       "11425  gói gọn doubledot hay tận_tình phù_hợp với mọi...           2\n",
       "\n",
       "[11426 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543920f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import collections\n",
    "from tqdm.notebook import tqdm\n",
    "import youtokentome as yttm\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class Vocabulary():\n",
    "  '''Vocabulary class: extract all words from corpus, save all words that appears more than freq_threshold times'''\n",
    "  def __init__(self, freq_threshold=3):\n",
    "    self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "    self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "    self.freq_threshold = freq_threshold\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.itos)\n",
    "\n",
    "  def build_vocab(self, sentence_list):\n",
    "    # Build the vocab\n",
    "    idx = 4\n",
    "    word_counter = collections.Counter([word for sentence in sentence_list for word in sentence])\n",
    "\n",
    "    for word, count in word_counter.items():\n",
    "      if count >= self.freq_threshold:\n",
    "        self.stoi[word] = idx\n",
    "        self.itos[idx] = word\n",
    "        idx += 1\n",
    "    # print(self.stoi)\n",
    "\n",
    "  def numericalize(self, sent):\n",
    "    # Turn a sentence into list of word ID\n",
    "    return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in sent\n",
    "        ]\n",
    "  def save_vocab(self, vocab_path):\n",
    "#     with open(itos_path, 'w') as itos_f:\n",
    "#         json.dump(self.itos, itos_f)\n",
    "#     with open(stoi_path, 'w') as stoi_f:\n",
    "#         json.dump(self.stoi, stoi_f)\n",
    "    with open(vocab_path, 'w') as f:\n",
    "        vocab = {'itos': self.itos, 'stoi': self.stoi}\n",
    "        json.dump(vocab, f)\n",
    "\n",
    "  def load_vocab(self, vocab_path):\n",
    "    with open(vocab_path, 'r') as f:\n",
    "#         print(type(itos_f.read()))\n",
    "        vocab = json.load(f)\n",
    "        self.itos = vocab['itos']\n",
    "        self.stoi = vocab['stoi']\n",
    "        \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d690a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df['sentiments'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5ce2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['slide', 'giáo_trình', 'đầy_đủ'],\n",
       " ['nhiệt_tình', 'giảng_dạy', 'gần_gũi', 'với', 'sinh_viên'],\n",
       " ['đi', 'học', 'đầy_đủ', 'full', 'điểm', 'chuyên', 'cần'],\n",
       " ['chưa',\n",
       "  'áp_dụng',\n",
       "  'công_nghệ_thông_tin',\n",
       "  'và',\n",
       "  'các',\n",
       "  'thiết_bị',\n",
       "  'hỗ_trợ',\n",
       "  'cho',\n",
       "  'việc',\n",
       "  'giảng_dạy'],\n",
       " ['thầy',\n",
       "  'giảng',\n",
       "  'bài',\n",
       "  'hay',\n",
       "  'có',\n",
       "  'nhiều',\n",
       "  'bài_tập',\n",
       "  'ví_dụ',\n",
       "  'ngay',\n",
       "  'trên',\n",
       "  'lớp']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = train_df['sentences'].values\n",
    "train_sents = [sent.split(\" \") for sent in train_sents]\n",
    "train_sents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d6652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(3)\n",
    "vocab.build_vocab(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a102325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " '<UNK>': 3,\n",
       " 'slide': 4,\n",
       " 'giáo_trình': 5,\n",
       " 'đầy_đủ': 6,\n",
       " 'nhiệt_tình': 7,\n",
       " 'giảng_dạy': 8,\n",
       " 'gần_gũi': 9,\n",
       " 'với': 10,\n",
       " 'sinh_viên': 11,\n",
       " 'đi': 12,\n",
       " 'học': 13,\n",
       " 'điểm': 14,\n",
       " 'chuyên': 15,\n",
       " 'cần': 16,\n",
       " 'chưa': 17,\n",
       " 'áp_dụng': 18,\n",
       " 'công_nghệ_thông_tin': 19,\n",
       " 'và': 20,\n",
       " 'các': 21,\n",
       " 'thiết_bị': 22,\n",
       " 'hỗ_trợ': 23,\n",
       " 'cho': 24,\n",
       " 'việc': 25,\n",
       " 'thầy': 26,\n",
       " 'giảng': 27,\n",
       " 'bài': 28,\n",
       " 'hay': 29,\n",
       " 'có': 30,\n",
       " 'nhiều': 31,\n",
       " 'bài_tập': 32,\n",
       " 'ví_dụ': 33,\n",
       " 'ngay': 34,\n",
       " 'trên': 35,\n",
       " 'lớp': 36,\n",
       " 'giảng_viên': 37,\n",
       " 'đảm_bảo': 38,\n",
       " 'thời_gian': 39,\n",
       " 'lên': 40,\n",
       " 'tích_cực': 41,\n",
       " 'trả_lời': 42,\n",
       " 'câu_hỏi': 43,\n",
       " 'của': 44,\n",
       " 'thường_xuyên': 45,\n",
       " 'đặt': 46,\n",
       " 'câu': 47,\n",
       " 'hỏi': 48,\n",
       " 'em': 49,\n",
       " 'sẽ': 50,\n",
       " 'môn': 51,\n",
       " 'này': 52,\n",
       " 'nhưng': 53,\n",
       " 'học_lại': 54,\n",
       " 'ở': 55,\n",
       " 'học_kỳ': 56,\n",
       " 'thời_lượng': 57,\n",
       " 'quá': 58,\n",
       " 'dài': 59,\n",
       " 'không': 60,\n",
       " 'tiếp_thu': 61,\n",
       " 'hiệu_quả': 62,\n",
       " 'nội_dung': 63,\n",
       " 'môn_học': 64,\n",
       " 'phần': 65,\n",
       " 'thiếu': 66,\n",
       " 'trọng_tâm': 67,\n",
       " 'hầu_như': 68,\n",
       " 'là': 69,\n",
       " 'chung_chung': 70,\n",
       " 'khái_quát': 71,\n",
       " 'khiến': 72,\n",
       " 'rất': 73,\n",
       " 'khó': 74,\n",
       " 'nắm': 75,\n",
       " 'được': 76,\n",
       " 'nói': 77,\n",
       " 'rõ': 78,\n",
       " 'hơn': 79,\n",
       " 'bằng': 80,\n",
       " 'cách': 81,\n",
       " 'trình_bày': 82,\n",
       " 'bảng': 83,\n",
       " 'thay_vì': 84,\n",
       " 'nhìn': 85,\n",
       " 'vào': 86,\n",
       " 'tận_tình': 87,\n",
       " 'dạy': 88,\n",
       " 'đúng': 89,\n",
       " 'giờ': 90,\n",
       " 'dễ': 91,\n",
       " 'bị': 92,\n",
       " 'áp_lực': 93,\n",
       " 'đang': 94,\n",
       " '<name>': 95,\n",
       " 'qua': 96,\n",
       " 'nước_ngoài': 97,\n",
       " 'giữa_chừng': 98,\n",
       " 'thay': 99,\n",
       " 'còn': 100,\n",
       " 'nâng': 101,\n",
       " 'độ': 102,\n",
       " 'nữa': 103,\n",
       " 'có_thể': 104,\n",
       " 'công_ty': 105,\n",
       " 'xem': 106,\n",
       " 'quy_mô': 107,\n",
       " 'làm_việc': 108,\n",
       " 'để': 109,\n",
       " 'giúp': 110,\n",
       " 'hiểu': 111,\n",
       " 'vê': 112,\n",
       " 'ngành': 113,\n",
       " 'mình': 114,\n",
       " 'hài_lòng': 115,\n",
       " 'về': 116,\n",
       " 'tất_cả': 117,\n",
       " 'vui_vẻ': 118,\n",
       " 'thấy': 119,\n",
       " 'trong': 120,\n",
       " 'trao_đổi': 121,\n",
       " 'giúp_đỡ': 122,\n",
       " 'học_tập': 123,\n",
       " 'phong_cách': 124,\n",
       " 'kết_hợp': 125,\n",
       " 'hoạt_động': 126,\n",
       " 'tạo': 127,\n",
       " 'buổi': 128,\n",
       " 'seminar': 129,\n",
       " 'sâu': 130,\n",
       " 'thêm': 131,\n",
       " 'vấn_đề': 132,\n",
       " 'chuyên_ngành': 133,\n",
       " 'tiết': 134,\n",
       " 'thoải_mái': 135,\n",
       " 'quan_tâm': 136,\n",
       " 'tới': 137,\n",
       " 'hướng_dẫn': 138,\n",
       " 'chi_tiết': 139,\n",
       " 'đến': 140,\n",
       " 'lúc': 141,\n",
       " 'làm': 142,\n",
       " 'tập': 143,\n",
       " 'chữa': 144,\n",
       " 'tài_liệu': 145,\n",
       " 'bổ_sung': 146,\n",
       " 'moodle': 147,\n",
       " 'phải': 148,\n",
       " 'nên': 149,\n",
       " 'cụ_thể': 150,\n",
       " 'những': 151,\n",
       " 'quan_trọng': 152,\n",
       " 'kỹ': 153,\n",
       " 'lấy': 154,\n",
       " 'minh_họa': 155,\n",
       " 'tránh': 156,\n",
       " 'lập': 157,\n",
       " 'lại': 158,\n",
       " 'lần': 159,\n",
       " 'cảm_giác': 160,\n",
       " 'chán': 161,\n",
       " 'biên_soạn': 162,\n",
       " 'một': 163,\n",
       " 'ta': 164,\n",
       " 'xung_quanh': 165,\n",
       " 'đa_dạng': 166,\n",
       " 'yêu': 167,\n",
       " 'tham_khảo': 168,\n",
       " 'ít': 169,\n",
       " 'ứng_dụng': 170,\n",
       " 'thực_tế': 171,\n",
       " 'đề_nghị': 172,\n",
       " 'sự': 173,\n",
       " 'thay_đổi': 174,\n",
       " 'up': 175,\n",
       " 'trước': 176,\n",
       " 'mỗi': 177,\n",
       " 'nhàm_chán': 178,\n",
       " 'khô_khan': 179,\n",
       " 'lượng': 180,\n",
       " 'kiến_thức': 181,\n",
       " 'chép': 182,\n",
       " 'giải_quyết': 183,\n",
       " 'thắc_mắc': 184,\n",
       " 'chúc': 185,\n",
       " 'thầy_cô': 186,\n",
       " 'anh_chị': 187,\n",
       " 'mặc_dù': 188,\n",
       " 'khi': 189,\n",
       " 'truyền_đạt': 190,\n",
       " 'thì': 191,\n",
       " 'sử_dụng': 192,\n",
       " 'gây': 193,\n",
       " 'khó_khăn': 194,\n",
       " 'khá': 195,\n",
       " 'cung_cấp': 196,\n",
       " 'thông_tin': 197,\n",
       " 'liên_quan': 198,\n",
       " 'đưa': 199,\n",
       " 'ra': 200,\n",
       " 'hướng': 201,\n",
       " 'gặp': 202,\n",
       " 'đồ_án': 203,\n",
       " 'hy_vọng': 204,\n",
       " 'sau': 205,\n",
       " 'cô': 206,\n",
       " 'đặc_tả': 207,\n",
       " 'hình_thức': 208,\n",
       " 'giống': 209,\n",
       " 'như': 210,\n",
       " 'lớp_học': 211,\n",
       " 'mà': 212,\n",
       " 'biết': 213,\n",
       " 'cái': 214,\n",
       " 'gì': 215,\n",
       " 'nói_nhỏ': 216,\n",
       " 'thực_hành': 217,\n",
       " 'tận_tâm': 218,\n",
       " 'sâu_rộng': 219,\n",
       " 'am_hiểu': 220,\n",
       " 'cao': 221,\n",
       " 'nhiệt_huyết': 222,\n",
       " 'dù': 223,\n",
       " 'thế_nào': 224,\n",
       " 'vẫn': 225,\n",
       " 'luôn': 226,\n",
       " 'cười': 227,\n",
       " 'chúng_em': 228,\n",
       " 'chúng': 229,\n",
       " 'lên_lớp': 230,\n",
       " 'cần_thiết': 231,\n",
       " 'doubledot': 232,\n",
       " 'nộp': 233,\n",
       " 'thường': 234,\n",
       " 'dặn': 235,\n",
       " 'thứ': 236,\n",
       " 'hai': 237,\n",
       " 'dễ_chịu': 238,\n",
       " 'bản_chất': 239,\n",
       " 'chỉ': 240,\n",
       " 'thôi': 241,\n",
       " 'nó': 242,\n",
       " 'sau_này': 243,\n",
       " 'nghành': 244,\n",
       " 'đặc_biệt': 245,\n",
       " 'đã': 246,\n",
       " 'bỏ': 247,\n",
       " 'công_sức': 248,\n",
       " 'chấm': 249,\n",
       " 'một_cách': 250,\n",
       " 'rõ_ràng': 251,\n",
       " 'minh_bạch': 252,\n",
       " 'tận_dụng': 253,\n",
       " 'tốt': 254,\n",
       " 'code': 255,\n",
       " 'nâng_cấp': 256,\n",
       " 'hệ_thống': 257,\n",
       " 'wifi': 258,\n",
       " 'vì': 259,\n",
       " 'phòng': 260,\n",
       " 'không_thể': 261,\n",
       " 'truy_cập': 262,\n",
       " 'internet': 263,\n",
       " 'buộc': 264,\n",
       " 'xin': 265,\n",
       " 'phép': 266,\n",
       " 'ngoài': 267,\n",
       " 'lắm': 268,\n",
       " 'vui_tính': 269,\n",
       " 'gần': 270,\n",
       " 'học_sinh': 271,\n",
       " 'buồn_ngủ': 272,\n",
       " 'mong': 273,\n",
       " 'giảm': 274,\n",
       " 'tải': 275,\n",
       " 'phù_hợp': 276,\n",
       " 'đặc_thù': 277,\n",
       " 'trường': 278,\n",
       " 'kiểu': 279,\n",
       " 'khó_tính': 280,\n",
       " 'hứng_thú': 281,\n",
       " 'cuốn_hút': 282,\n",
       " 'ôn_tập': 283,\n",
       " 'theo': 284,\n",
       " 'cuối': 285,\n",
       " 'kỳ': 286,\n",
       " 'mấy': 287,\n",
       " 'khác': 288,\n",
       " 'nhau': 289,\n",
       " 'giáo_viên': 290,\n",
       " 'nghỉ': 291,\n",
       " 'liên_tục': 292,\n",
       " 'tăng': 293,\n",
       " 'bù': 294,\n",
       " 'đó': 295,\n",
       " 'ảnh_hưởng': 296,\n",
       " 'trễ': 297,\n",
       " 'deadline': 298,\n",
       " 'cũng': 299,\n",
       " 'thông_báo': 300,\n",
       " 'tốn': 301,\n",
       " 'rồi': 302,\n",
       " 'ngồi': 303,\n",
       " 'đợi': 304,\n",
       " 'máy': 305,\n",
       " 'hiện_đại': 306,\n",
       " 'tương_tự': 307,\n",
       " 'một_vài': 308,\n",
       " 'tình_trạng': 309,\n",
       " 'quên': 310,\n",
       " 'hoặc': 311,\n",
       " 'dạng': 312,\n",
       " 'hơi': 313,\n",
       " 'vậy': 314,\n",
       " 'từ': 315,\n",
       " '30': 316,\n",
       " '45': 317,\n",
       " 'phút': 318,\n",
       " 'đánh_giá': 319,\n",
       " 'sai': 320,\n",
       " 'năng_lực': 321,\n",
       " 'đáp_ứng': 322,\n",
       " 'đề_cương': 323,\n",
       " 'đề': 324,\n",
       " 'thân_thiện': 325,\n",
       " 'lập_trình': 326,\n",
       " 'đối_tượng': 327,\n",
       " 'cập_nhật': 328,\n",
       " 'mới': 329,\n",
       " 'giảng_giải': 330,\n",
       " 'tâm_huyết': 331,\n",
       " 'khả_năng': 332,\n",
       " 'nhỏ': 333,\n",
       " 'nếu': 334,\n",
       " 'ồn': 335,\n",
       " 'nghe': 336,\n",
       " 'tìm_hiểu': 337,\n",
       " 'kiến': 338,\n",
       " 'thực_hiện': 339,\n",
       " 'tại': 340,\n",
       " 'nhóm': 341,\n",
       " 'phương_pháp': 342,\n",
       " 'nắm_bắt': 343,\n",
       " 'kinh_nghiệm': 344,\n",
       " 'bảo_đảm': 345,\n",
       " 'hiện_tại': 346,\n",
       " 'tác_dụng': 347,\n",
       " 'cải_thiện': 348,\n",
       " 'cơ_sở_vật_chất': 349,\n",
       " 'chiếu': 350,\n",
       " 'phòng_học': 351,\n",
       " 'giải_thích': 352,\n",
       " 'đông': 353,\n",
       " 'căn_bản': 354,\n",
       " 'mất': 355,\n",
       " 'nhà': 356,\n",
       " '5': 357,\n",
       " 'chương': 358,\n",
       " 'đáp_án': 359,\n",
       " 'đây': 360,\n",
       " 'lớn': 361,\n",
       " 'đối_với': 362,\n",
       " 'tụi': 363,\n",
       " 'tôi': 364,\n",
       " 'cảm_thấy': 365,\n",
       " 'nào': 366,\n",
       " 'chính_thức': 367,\n",
       " 'đứng': 368,\n",
       " 'chờ': 369,\n",
       " 'sắp': 370,\n",
       " 'hết': 371,\n",
       " 'tự': 372,\n",
       " 'tương_tác': 373,\n",
       " 'giữa': 374,\n",
       " 'cởi_mở': 375,\n",
       " 'mời': 376,\n",
       " 'thực_tiễn': 377,\n",
       " 'coi': 378,\n",
       " 'thái_độ': 379,\n",
       " 'giải': 380,\n",
       " 'thu_hút': 381,\n",
       " 'nhanh': 382,\n",
       " 'kém': 383,\n",
       " 'hợp_lý': 384,\n",
       " 'tập_trung': 385,\n",
       " 'bài_giảng': 386,\n",
       " 'nhờ': 387,\n",
       " 'lý_thuyết': 388,\n",
       " 'trừu_tượng': 389,\n",
       " 'số': 390,\n",
       " 'cơ_hội': 391,\n",
       " 'đáp': 392,\n",
       " 'song_song': 393,\n",
       " 'giới_thiệu': 394,\n",
       " 'đầu': 395,\n",
       " 'đọc': 396,\n",
       " 'suy_nghĩ': 397,\n",
       " 'cùng': 398,\n",
       " 'ai': 399,\n",
       " 'người': 400,\n",
       " 'ấy': 401,\n",
       " 'phản_hồi': 402,\n",
       " 'giải_đáp': 403,\n",
       " 'ban': 404,\n",
       " 'sớm': 405,\n",
       " 'khắc_phục': 406,\n",
       " 'ạ': 407,\n",
       " 'đề_tài': 408,\n",
       " 'hiếm': 409,\n",
       " 'nhớ': 410,\n",
       " 'đa_số': 411,\n",
       " 'đổi_mới': 412,\n",
       " 'hấp_dẫn': 413,\n",
       " 'chủ_động': 414,\n",
       " 'tiếp_cận': 415,\n",
       " 'tham_gia': 416,\n",
       " 'chương_trình': 417,\n",
       " 'kỹ_năng': 418,\n",
       " 'nhu_cầu': 419,\n",
       " 'điều': 420,\n",
       " 'hiễu': 421,\n",
       " 'dễ_thương': 422,\n",
       " 'nhà_trường': 423,\n",
       " 'lãng_phí': 424,\n",
       " '2': 425,\n",
       " 'có_lẽ': 426,\n",
       " 'daa': 427,\n",
       " 'nhầm': 428,\n",
       " 'thi': 429,\n",
       " 'đủ': 430,\n",
       " 'test': 431,\n",
       " 'visual': 432,\n",
       " 'trở': 433,\n",
       " 'nhất': 434,\n",
       " 'sôi_động': 435,\n",
       " 'xác_định': 436,\n",
       " 'mục_đích': 437,\n",
       " 'bắt_đầu': 438,\n",
       " 'nói_chuyện': 439,\n",
       " 'tự_nhiên': 440,\n",
       " 'chia_sẻ': 441,\n",
       " 'sát': 442,\n",
       " 'trang_thiết_bị': 443,\n",
       " 'phục_vụ': 444,\n",
       " 'lab': 445,\n",
       " 'khoa': 446,\n",
       " 'mạng': 447,\n",
       " 'tính': 448,\n",
       " 'yêu_cầu': 449,\n",
       " 'đươc': 450,\n",
       " 'chính_xác': 451,\n",
       " 'chia': 452,\n",
       " 'vài': 453,\n",
       " 'thoáng': 454,\n",
       " 'chuẩn_bị': 455,\n",
       " 'một_số': 456,\n",
       " 'trở_nên': 457,\n",
       " 'lỗi_thời': 458,\n",
       " 'nghiên_cứu': 459,\n",
       " 'khoa_học': 460,\n",
       " 'gặp_mặt': 461,\n",
       " 'lịch': 462,\n",
       " 'cố_định': 463,\n",
       " 'trực_tiếp': 464,\n",
       " 'sai_sót': 465,\n",
       " 'viết': 466,\n",
       " 'chổ': 467,\n",
       " 'quan_sát': 468,\n",
       " 'lắp': 469,\n",
       " 'quạt': 470,\n",
       " 'sửa': 471,\n",
       " 'cách_thức': 472,\n",
       " 'kiểm_tra': 473,\n",
       " 'sôi_nổi': 474,\n",
       " 'truyền_cảm': 475,\n",
       " 'mẫu': 476,\n",
       " 'kênh': 477,\n",
       " 'bạn': 478,\n",
       " 'công_thức': 479,\n",
       " 'cả': 480,\n",
       " 'thực_sự': 481,\n",
       " 'nguyên_lý': 482,\n",
       " 'cơ_bản': 483,\n",
       " 'bao_gồm': 484,\n",
       " '7': 485,\n",
       " 'nguyên_tắc': 486,\n",
       " 'tân': 487,\n",
       " 'tâm': 488,\n",
       " 'lẫn': 489,\n",
       " 'bên': 490,\n",
       " 'thầy_giáo': 491,\n",
       " 'cố_gắng': 492,\n",
       " 'hoà_đồng': 493,\n",
       " 'ham': 494,\n",
       " 'học_hỏi': 495,\n",
       " 'tiết_thực_hành': 496,\n",
       " 'thống_nhất': 497,\n",
       " 'bộ_môn': 498,\n",
       " 'nửa': 499,\n",
       " 'nghĩ': 500,\n",
       " 'máy_tính': 501,\n",
       " 'vui': 502,\n",
       " 'hòa': 503,\n",
       " 'đồng_nhiệt_tình': 504,\n",
       " 'tuy_nhiên': 505,\n",
       " 'cân_nhắc': 506,\n",
       " 'số_lượng': 507,\n",
       " 'khớp': 508,\n",
       " 'dẫn': 509,\n",
       " 'qua_loa': 510,\n",
       " 'kết_quả': 511,\n",
       " 'ok': 512,\n",
       " 'thích': 513,\n",
       " 'tí': 514,\n",
       " 'xem_xét': 515,\n",
       " 'vừa': 516,\n",
       " 'động_lực': 517,\n",
       " 'mức_độ': 518,\n",
       " 'hiểu_biết': 519,\n",
       " 'nói_chung': 520,\n",
       " 'bao_giờ': 521,\n",
       " 'sức': 522,\n",
       " 'cô_giáo': 523,\n",
       " 'cải_tiến': 524,\n",
       " 'trang': 525,\n",
       " 'kéo': 526,\n",
       " 'hiền': 527,\n",
       " 'đôi': 528,\n",
       " 'nền_tảng': 529,\n",
       " 'dễ_dàng': 530,\n",
       " 'công_nghệ': 531,\n",
       " 'nhanh_chóng': 532,\n",
       " 'cấu_trúc': 533,\n",
       " 'toàn': 534,\n",
       " 'tiếng': 535,\n",
       " 'anh': 536,\n",
       " 'nhận': 537,\n",
       " 'hề': 538,\n",
       " 'tuần': 539,\n",
       " 'đều': 540,\n",
       " 'cảm_ơn': 541,\n",
       " 'xong': 542,\n",
       " 'thưc': 543,\n",
       " 'hành': 544,\n",
       " 'chuyện': 545,\n",
       " 'riêng': 546,\n",
       " 'giáo': 547,\n",
       " 'viện': 548,\n",
       " 'kit': 549,\n",
       " 'ý_kiến': 550,\n",
       " 'sắp_xếp': 551,\n",
       " 'thời_khóa_biểu': 552,\n",
       " 'bắt_buộc': 553,\n",
       " '1': 554,\n",
       " 'năm': 555,\n",
       " 'nhằm': 556,\n",
       " 'đòi_hỏi': 557,\n",
       " 'hướng_dẫn_nhiệt_tình': 558,\n",
       " 'giấy': 559,\n",
       " 'mô_hình': 560,\n",
       " 'phức_tạp': 561,\n",
       " 'đánh': 562,\n",
       " 'muốn': 563,\n",
       " 'công_bằng': 564,\n",
       " 'cúp': 565,\n",
       " 'mà_còn': 566,\n",
       " 'mở_rộng': 567,\n",
       " 'tăng_cường': 568,\n",
       " 'giao_tiếp': 569,\n",
       " 'điều_kiện': 570,\n",
       " 'bám': 571,\n",
       " 'chính': 572,\n",
       " 'đoạn': 573,\n",
       " 'giải_thuật': 574,\n",
       " 'bài_toán': 575,\n",
       " 'nguồn': 576,\n",
       " 'thú_vị': 577,\n",
       " 'lý_do': 578,\n",
       " 'hệ': 579,\n",
       " 'tài_năng': 580,\n",
       " 'sở': 581,\n",
       " 'mới_mẻ': 582,\n",
       " 'mắc': 583,\n",
       " 'rớt': 584,\n",
       " 'góp_ý': 585,\n",
       " 'từng': 586,\n",
       " 'cắm': 587,\n",
       " 'dụng_cụ': 588,\n",
       " 'virus': 589,\n",
       " 'liên_hệ': 590,\n",
       " 'rèm': 591,\n",
       " 'che': 592,\n",
       " 'sáng': 593,\n",
       " 'dạy_học': 594,\n",
       " 'khoá': 595,\n",
       " 'mục': 596,\n",
       " 'lặp': 597,\n",
       " 'khảo_sát': 598,\n",
       " 'tích': 599,\n",
       " 'hoc': 600,\n",
       " 'sinh': 601,\n",
       " 'mọi': 602,\n",
       " 'tự_tin': 603,\n",
       " 'to': 604,\n",
       " 'giọng': 605,\n",
       " 'micro': 606,\n",
       " 'phương_pháp_học_tập': 607,\n",
       " 'chút': 608,\n",
       " 'thuyết_trình': 609,\n",
       " 'liệu': 610,\n",
       " 'chuẩn_xác': 611,\n",
       " 'nghiêm_túc': 612,\n",
       " 'không_khí': 613,\n",
       " 'lúc_nào': 614,\n",
       " 'thậm_chí': 615,\n",
       " 'tin': 616,\n",
       " 'cấp': 617,\n",
       " '3': 618,\n",
       " 'tận_tụy': 619,\n",
       " 'chuyển': 620,\n",
       " 'ngủ': 621,\n",
       " 'cơ_mà': 622,\n",
       " 'colonlove': 623,\n",
       " 'bao_quát': 624,\n",
       " 'đề_cập': 625,\n",
       " 'khía_cạnh': 626,\n",
       " 'bài_học': 627,\n",
       " 'hoàn_thành': 628,\n",
       " 'nhẹ': 629,\n",
       " 'chung': 630,\n",
       " 'kích_thích': 631,\n",
       " 'sáng_tạo': 632,\n",
       " 'ngừng': 633,\n",
       " 'xây_dựng': 634,\n",
       " 'chức_năng': 635,\n",
       " 'chú_trọng': 636,\n",
       " 'ngữ_pháp': 637,\n",
       " 'rộng': 638,\n",
       " 'truyền_cảm_hứng': 639,\n",
       " 'sinh_động': 640,\n",
       " 'thực_trạng': 641,\n",
       " 'tiến_độ': 642,\n",
       " 'do': 643,\n",
       " 'chấm_bài': 644,\n",
       " 'mệt_mỏi': 645,\n",
       " 'phần_nào': 646,\n",
       " 'phong_phú': 647,\n",
       " 'tháng': 648,\n",
       " 'lề': 649,\n",
       " 'thật': 650,\n",
       " 'lan_man': 651,\n",
       " 'phân_bổ': 652,\n",
       " 'video': 653,\n",
       " 'bận': 654,\n",
       " 'hi_vọng': 655,\n",
       " 'cảm_hứng': 656,\n",
       " 'chậm': 657,\n",
       " 'cặn_kẽ': 658,\n",
       " 'đôi_khi': 659,\n",
       " 'đem': 660,\n",
       " 'cứ': 661,\n",
       " '10': 662,\n",
       " 'chắc_chắn': 663,\n",
       " 'tốt_bụng': 664,\n",
       " 'chỗ': 665,\n",
       " 'mục_tiêu': 666,\n",
       " 'bước': 667,\n",
       " 'khối_lượng': 668,\n",
       " 'kịp_thời': 669,\n",
       " 'ổ_cắm': 670,\n",
       " 'laptop': 671,\n",
       " 'màn': 672,\n",
       " 'cửa_sổ': 673,\n",
       " 'theo_dõi': 674,\n",
       " 'bớt': 675,\n",
       " 'âm_thanh': 676,\n",
       " 'chất_lượng': 677,\n",
       " 'tệ': 678,\n",
       " 'ngắn_gọn': 679,\n",
       " 'giỏi': 680,\n",
       " 'chu_đáo': 681,\n",
       " 'tuy': 682,\n",
       " 'chém': 683,\n",
       " 'gió': 684,\n",
       " 'gửi': 685,\n",
       " 'email': 686,\n",
       " 'show': 687,\n",
       " 'loa': 688,\n",
       " 'niềm': 689,\n",
       " 'bọn': 690,\n",
       " 'đuối': 691,\n",
       " 'hài_hước': 692,\n",
       " 'thẳng': 693,\n",
       " 'đẹp_trai': 694,\n",
       " 'trò_chuyện': 695,\n",
       " 'rằng': 696,\n",
       " 'ngoài_ra': 697,\n",
       " 'hòa_đồng': 698,\n",
       " 'truyền_tải': 699,\n",
       " 'giúp_ích': 700,\n",
       " 'chi': 701,\n",
       " 'tìm_kiếm': 702,\n",
       " 'đâu': 703,\n",
       " 'chứ': 704,\n",
       " 'phương_thức': 705,\n",
       " 'hàm': 706,\n",
       " 'chú_ý': 707,\n",
       " 'luyện_tập': 708,\n",
       " 'phần_mềm': 709,\n",
       " 'hiêu': 710,\n",
       " 'thương_sinh_viên': 711,\n",
       " 'tổ_chức': 712,\n",
       " 'học_viên': 713,\n",
       " 'vững': 714,\n",
       " 'hạn': 715,\n",
       " 'báo_cáo': 716,\n",
       " 'khuyến_khích': 717,\n",
       " 'cuối_cùng': 718,\n",
       " 'công_bố': 719,\n",
       " 'toán': 720,\n",
       " 'hãy': 721,\n",
       " 'điểm_danh': 722,\n",
       " 'đại_học': 723,\n",
       " 'phổ_thông': 724,\n",
       " 'cực_kỳ': 725,\n",
       " 'học_trò': 726,\n",
       " 'khách_quan': 727,\n",
       " 'công_việc': 728,\n",
       " 'giữ': 729,\n",
       " 'sức_khỏe': 730,\n",
       " 'colonsmile': 731,\n",
       " 'vừa_sức': 732,\n",
       " 'như_vậy': 733,\n",
       " 'mơ_hồ': 734,\n",
       " 'áp_đặt': 735,\n",
       " 'lỗi': 736,\n",
       " 'sửa_chữa': 737,\n",
       " 'việc_làm': 738,\n",
       " 'colonsad': 739,\n",
       " 'nêu': 740,\n",
       " 'yêu_thích': 741,\n",
       " 'vòng': 742,\n",
       " 'bữa': 743,\n",
       " 'file': 744,\n",
       " 'lôi_cuốn': 745,\n",
       " 'mạch': 746,\n",
       " 'lạc_đề': 747,\n",
       " 'phân_chia': 748,\n",
       " 'học_phần': 749,\n",
       " 'rút': 750,\n",
       " 'ngắn': 751,\n",
       " 'tiêu_chí': 752,\n",
       " 'tâm_lý': 753,\n",
       " 'tranh_luận': 754,\n",
       " 'đào_sâu': 755,\n",
       " 'kỹ_thuật': 756,\n",
       " 'tình_hình': 757,\n",
       " 'thi_cử': 758,\n",
       " 'tư_duy': 759,\n",
       " 'logic': 760,\n",
       " 'chủ_yếu': 761,\n",
       " 'project': 762,\n",
       " 'trục_trặc': 763,\n",
       " 'quá_trình': 764,\n",
       " 'giờ_giấc': 765,\n",
       " 'hư_hỏng': 766,\n",
       " 'khô_cứng': 767,\n",
       " 'nhập_môn': 768,\n",
       " 'điện_tử': 769,\n",
       " 'thiết_nghĩ': 770,\n",
       " 'đồng_thời': 771,\n",
       " 'đam_mê': 772,\n",
       " 'ngày': 773,\n",
       " 'cơ_sở': 774,\n",
       " 'dữ_liệu': 775,\n",
       " 'nay': 776,\n",
       " 'thiết_kế': 777,\n",
       " 'trắc_nghiệm': 778,\n",
       " 'luôn_luôn': 779,\n",
       " 'thói_quen': 780,\n",
       " 'vô_cùng': 781,\n",
       " 'bổ_ích': 782,\n",
       " 'bàn_ghế': 783,\n",
       " 'bụi': 784,\n",
       " 'kể': 785,\n",
       " 'đầy': 786,\n",
       " '9': 787,\n",
       " 'nhắc': 788,\n",
       " 'về_phần': 789,\n",
       " 'hôm': 790,\n",
       " 'mày_mò': 791,\n",
       " 'xuống': 792,\n",
       " 'mong_muốn': 793,\n",
       " 'giáo_án': 794,\n",
       " 'diễn_đạt': 795,\n",
       " 'cách_diễn_đạt': 796,\n",
       " 'trực_quan': 797,\n",
       " 'chữ': 798,\n",
       " 'hạn_chế': 799,\n",
       " 'văn': 800,\n",
       " 'tròn': 801,\n",
       " 'con': 802,\n",
       " 'kịp': 803,\n",
       " 'bảo': 804,\n",
       " 'phấn_đấu': 805,\n",
       " 'đời': 806,\n",
       " 'đỡ': 807,\n",
       " 'bối_rối': 808,\n",
       " 'sách': 809,\n",
       " 'colonsmilesmile': 810,\n",
       " 'bất_kỳ': 811,\n",
       " 'quản_trị': 812,\n",
       " 'mang': 813,\n",
       " 'xin_lỗi': 814,\n",
       " 'linh_động': 815,\n",
       " 'nhận_thức': 816,\n",
       " 'chọn': 817,\n",
       " 'lựa_chọn': 818,\n",
       " 'kinh_tế': 819,\n",
       " 'rèn_luyện': 820,\n",
       " 'mặt': 821,\n",
       " 'colondoublesurprise': 822,\n",
       " 'triển_khai': 823,\n",
       " 'khung': 824,\n",
       " 'thông_qua': 825,\n",
       " 'lẫn_lộn': 826,\n",
       " 'việt': 827,\n",
       " 'dùng': 828,\n",
       " 'google': 829,\n",
       " 'dịch': 830,\n",
       " 'tuyệt_vời': 831,\n",
       " 'cũ': 832,\n",
       " 'khắt_khe': 833,\n",
       " 'hiện_nay': 834,\n",
       " 'tốc_độ': 835,\n",
       " 'ôn': 836,\n",
       " 'càng': 837,\n",
       " 'đầu_tư': 838,\n",
       " 'mượn': 839,\n",
       " 'điện_thoại': 840,\n",
       " 'android': 841,\n",
       " 'windows': 842,\n",
       " 'phone': 843,\n",
       " 'tỉ_mỉ': 844,\n",
       " 'tiền': 845,\n",
       " 'họ': 846,\n",
       " 'tùy': 847,\n",
       " 'đóng_góp': 848,\n",
       " 'nước': 849,\n",
       " 'hội_thảo': 850,\n",
       " 'share': 851,\n",
       " 'trang_bị': 852,\n",
       " 'miền': 853,\n",
       " 'giấc': 854,\n",
       " 'tuân_thủ': 855,\n",
       " 'gọn': 856,\n",
       " 'khó_hiểu': 857,\n",
       " 'liên_lạc': 858,\n",
       " 'wireshark': 859,\n",
       " 'yếu_kém': 860,\n",
       " 'xa': 861,\n",
       " 'nóng': 862,\n",
       " 'củng_cố': 863,\n",
       " 'di_động': 864,\n",
       " 'mô_phỏng': 865,\n",
       " 'so': 866,\n",
       " 'đào_tạo': 867,\n",
       " 'bao': 868,\n",
       " 'toeic': 869,\n",
       " 'kính': 870,\n",
       " 'vận_dụng': 871,\n",
       " 'trình': 872,\n",
       " 'lời_nói': 873,\n",
       " 'tìm': 874,\n",
       " 'phân_loại': 875,\n",
       " 'định_hướng': 876,\n",
       " 'tương_lai': 877,\n",
       " 'cạnh': 878,\n",
       " 'công_trình': 879,\n",
       " 'ồn_ào': 880,\n",
       " 'vì_thế': 881,\n",
       " 'gián_đoạn': 882,\n",
       " 'thế': 883,\n",
       " 'dám': 884,\n",
       " 'mail': 885,\n",
       " 'đơn_giản': 886,\n",
       " 'bỏ_qua': 887,\n",
       " 'dựa': 888,\n",
       " 'lời': 889,\n",
       " 'khuyên': 890,\n",
       " 'hữu_ích': 891,\n",
       " 'lướt': 892,\n",
       " 'chuyên_môn': 893,\n",
       " 'hiền_lành': 894,\n",
       " 'năng_nổ': 895,\n",
       " 'cẩn_thận': 896,\n",
       " 'thật_sự': 897,\n",
       " 'nặng': 898,\n",
       " 'gộp': 899,\n",
       " 'thành': 900,\n",
       " 'nổi': 901,\n",
       " 'kết_nối': 902,\n",
       " 'luyện': 903,\n",
       " 'thiếu_sót': 904,\n",
       " 'hăng_hái': 905,\n",
       " 'phản_ánh': 906,\n",
       " 'it': 907,\n",
       " 'thiết_thực': 908,\n",
       " 'phát_âm': 909,\n",
       " '4': 910,\n",
       " 'phía': 911,\n",
       " 'đăng_ký': 912,\n",
       " 'speaking': 913,\n",
       " 'listening': 914,\n",
       " 'đồng_ý': 915,\n",
       " 'module': 916,\n",
       " 'demo': 917,\n",
       " 'ghi': 918,\n",
       " 'có_vẻ': 919,\n",
       " '2009': 920,\n",
       " 'máy_lạnh': 921,\n",
       " 'đẹp': 922,\n",
       " 'thể_hiện': 923,\n",
       " 'chuyên_nghiệp': 924,\n",
       " 'công_cụ': 925,\n",
       " 'thang': 926,\n",
       " 'khóa': 927,\n",
       " 'nhất_quán': 928,\n",
       " 'tư_tưởng': 929,\n",
       " 'thành_công': 930,\n",
       " 'bức_xúc': 931,\n",
       " 'ân_cần': 932,\n",
       " 'sẵn_sàng': 933,\n",
       " 'hết_mình': 934,\n",
       " 'nghề': 935,\n",
       " 'phụ': 936,\n",
       " 'hiện': 937,\n",
       " 'fraction': 938,\n",
       " 'giao': 939,\n",
       " 'áp': 940,\n",
       " 'dành': 941,\n",
       " 'hi_hi': 942,\n",
       " 'ổn': 943,\n",
       " 'học_hiệu_quả': 944,\n",
       " 'thân': 945,\n",
       " 'mờ': 946,\n",
       " 'quản_lý': 947,\n",
       " 'thuận_tiện': 948,\n",
       " 'cân_bằng': 949,\n",
       " 'yếu': 950,\n",
       " 'thành_viên': 951,\n",
       " 'muộn': 952,\n",
       " 'lòng': 953,\n",
       " 'thưa': 954,\n",
       " 'tương_đối': 955,\n",
       " 'cá_nhân': 956,\n",
       " 'sợ': 957,\n",
       " 'mạnh': 958,\n",
       " 'nhất_thiết': 959,\n",
       " 'thụ_động': 960,\n",
       " 'sư_phạm': 961,\n",
       " 'chủ_đề': 962,\n",
       " 'mở': 963,\n",
       " 'chat': 964,\n",
       " 'ổ': 965,\n",
       " 'điện': 966,\n",
       " 'dưới': 967,\n",
       " 'nền': 968,\n",
       " 'tiện': 969,\n",
       " 'kiên_nhẫn': 970,\n",
       " 'sửa_đổi': 971,\n",
       " 'dễ_tính': 972,\n",
       " 'chéo': 973,\n",
       " 'phụ_thuộc': 974,\n",
       " 'trình_độ': 975,\n",
       " 'quy_định': 976,\n",
       " 'đồng': 977,\n",
       " 'tình': 978,\n",
       " 'bao_nhiêu': 979,\n",
       " 'chân_thành': 980,\n",
       " 'chuẩn': 981,\n",
       " 'hình': 982,\n",
       " 'toàn_bộ': 983,\n",
       " 'dãy': 984,\n",
       " 'thuật_toán': 985,\n",
       " 'báo': 986,\n",
       " 'bày': 987,\n",
       " 'chuyên_sâu': 988,\n",
       " 'hời_hợt': 989,\n",
       " 'thảo_luận': 990,\n",
       " 'tự_ý': 991,\n",
       " 'sang': 992,\n",
       " 'thất_vọng': 993,\n",
       " 'ý': 994,\n",
       " 'ngoại_ngữ': 995,\n",
       " 'chỉ_dẫn': 996,\n",
       " 'hỏng_hóc': 997,\n",
       " 'xảy': 998,\n",
       " 'hướng_dẫn_giải': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b0302e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "seed  = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "  def __init__(self,df, vocab = None, max_sent_len = 120):\n",
    "    \n",
    "    self.train_sents = [sent.split(\" \") for sent in df['sentences'].values]\n",
    "    self.labels = df['sentiments'].values\n",
    "    self.max_sent_len = max_sent_len\n",
    "    if vocab == None:\n",
    "        self.vocab = Vocabulary(3)\n",
    "        self.vocab.build_vocab(self.train_sents)\n",
    "    else:\n",
    "        self.vocab = vocab\n",
    "  def __len__(self):\n",
    "    return len(self.train_sents)\n",
    "      \n",
    "  def __getitem__(self, index):\n",
    "    # Override __getitem__ method of parent class (torch.utils.data.Dataset class) \n",
    "    sent_numericalized = [self.vocab.stoi[\"<SOS>\"]]\n",
    "    sent_numericalized += self.vocab.numericalize(self.train_sents[index])\n",
    "    \n",
    "    if len(sent_numericalized) > self.max_sent_len:\n",
    "        sent_numericalized = sent_numericalized[:self.max_sent_len]\n",
    "\n",
    "    sent_tensor = np.full(self.max_sent_len, self.vocab.stoi[\"<PAD>\"])\n",
    "    sent_tensor[:len(sent_numericalized)] = sent_numericalized\n",
    "    x = torch.Tensor(sent_tensor).long()\n",
    "    \n",
    "    y = self.labels[index]\n",
    "#     y = torch.Tensor([y]).long()\n",
    "    return x,y\n",
    "  def get_dataset(self):\n",
    "    src = []\n",
    "    target = []\n",
    "    for index in range(len(self)):\n",
    "        x,y = self[index]\n",
    "        src.append(x)\n",
    "        \n",
    "#         print(x.shape, y)\n",
    "    src = torch.stack(sent, dim = 0)\n",
    "    return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e40efa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(df, vocab = None, max_sent_len = 120,batch_size = 64, num_workers = 0, shuffle = True, pin_memory = True):\n",
    "    '''\n",
    "    Function to create DataLoader: group sentences into batches of size batch_size\n",
    "    \n",
    "    Params:\n",
    "      src_data_file, tgt_data_file: path to source and target data file\n",
    "      max_seq_len: max number of tokens in a sentence\n",
    "      en_vocab, vi_vocab: object of Vocabulary class. If we already have en_vocab and vi_vocab, we avoid creating them again\n",
    "      back_translation: if we're using this for back translation, set this to True\n",
    "      batch_size: number of sentences in a batch\n",
    "      num_workers, shuffle, pin_memory: not very important\n",
    "    Returns:\n",
    "      loader: object of DataLoader class\n",
    "      dataset: object of StanfordEnViDataset class\n",
    "      en_vocab, vi_vocab: object of Vocabulary class. This is vocab of English and Vietnamese\n",
    "    '''\n",
    "#     dataset = StanfordEnViDataset(src_data_file, tgt_data_file, en_vocab_path, vi_vocab_path, input_type,bpe_en_file, bpe_vi_file, max_seq_len, back_translation)  \n",
    "    dataset = SentimentDataset(df, vocab = vocab, max_sent_len = max_sent_len)\n",
    "    vocab = dataset.vocab\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    return loader, dataset, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "70bdd27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,_,vocab = get_loader(train_df, vocab = None, max_sent_len = 100)\n",
    "val_loader,dev_dataset,_ = get_loader(val_df, vocab = vocab, max_sent_len = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0a781812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 1\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 2\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n",
      "torch.Size([100]) 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14108/3263860195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdev_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14108/1498074467.py\u001b[0m in \u001b[0;36mget_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "dev_dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed603747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1, 300,  13,  ...,   0,   0,   0],\n",
      "        [  1,   3, 149,  ...,   0,   0,   0],\n",
      "        [  1,  37,  88,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1,  37,  30,  ...,   0,   0,   0],\n",
      "        [  1, 426, 643,  ...,   0,   0,   0],\n",
      "        [  1, 206,  88,  ...,   0,   0,   0]]) tensor([0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0,\n",
      "        0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2,\n",
      "        2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2])\n",
      "torch.Size([64, 100]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (src, tgt) in enumerate(train_loader):\n",
    "    print(src, tgt)\n",
    "    print(src.shape,tgt.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d564e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx, device):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx).to(self.device)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ]).to(self.device)\n",
    "#         self.conv_1 = nn.ModuleList( [nn.Conv2d(in_channels = 1, out_channels = 128, kernel_size = 4, padding = 'same'),\n",
    "#                                       nn.ReLU()]).to(self.device)\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim).to(self.device)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "#         self.log_softmax = F.log_softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "#         print(embedded.shape)\n",
    "    \n",
    "#         embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "#         #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "#         pooled = self.conv_1(embedded)\n",
    "#         print(pooled.shape)\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        fc = self.relu(self.fc(self.dropout(cat)))\n",
    "        \n",
    "        \n",
    "        proba = F.softmax(fc, dim = 1)\n",
    "        \n",
    "        \n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "010f4d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3])\n"
     ]
    }
   ],
   "source": [
    "train_loader,_,vocab = get_loader(train_df, vocab = None, max_sent_len = 100)\n",
    "val_loader,_,_ = get_loader(val_df, vocab = vocab, max_sent_len = 100)\n",
    "\n",
    "PAD_IDX = vocab.stoi[\"<PAD>\"]\n",
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX, device = device)\n",
    "for batch_idx, (src, tgt) in enumerate(train_loader):\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    y = model(src)\n",
    "    print(y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ab43de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bc003792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, optimizer,src, tgt, criterion):\n",
    "  \"\"\"\n",
    "  Is called every step to train the model\n",
    "  \"\"\"\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  inp_data = src.to(device)\n",
    "  target = tgt.to(device)\n",
    "#   print(inp_data.shape, target.shape)\n",
    "\n",
    "  # forward prop\n",
    "  output = model(inp_data)\n",
    "#   print(output.shape)\n",
    "#   output = output.reshape(-1, output.shape[2])\n",
    "#   target = target[:, 1:].reshape(-1)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  loss = criterion(output, target)\n",
    "  loss.backward()\n",
    "  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "  optimizer.step()\n",
    "  lr = optimizer.param_groups[0][\"lr\"]\n",
    "#   scheduler.step()\n",
    "  \n",
    "  \n",
    "  \n",
    "  return loss.item() , lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6fcd6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,dev_loader, criterion, scheduler):\n",
    "  eval_losses = []\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for idx, (src, tgt) in enumerate(dev_loader):\n",
    "        inp_data = src.to(device)\n",
    "        target = tgt.to(device)\n",
    "          # forward prop\n",
    "        output = model(inp_data)\n",
    "        eval_loss = criterion(output, target)\n",
    "        eval_losses.append(eval_loss.item())\n",
    "  mean_eval_loss = sum(eval_losses) / len(eval_losses)\n",
    "  scheduler.step(mean_eval_loss)\n",
    "  return mean_eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cd985c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, file_name):\n",
    "    torch.save(state, file_name)\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_path,map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"], strict = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1e1569e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Classifier():\n",
    "    def __init__(self, config, device):\n",
    "      seed  = 42\n",
    "      torch.manual_seed(seed)\n",
    "      torch.cuda.manual_seed_all(seed)\n",
    "      torch.cuda.manual_seed(seed)\n",
    "      np.random.seed(seed)\n",
    "      random.seed(seed)\n",
    "      torch.backends.cudnn.deterministic = True\n",
    "      torch.backends.cudnn.benchmark = False\n",
    "\n",
    "      self.config = config\n",
    "      self.device = device\n",
    "      self.max_sent_len = self.config['model']['max_sent_len']\n",
    "      self.train_loader,_,self.vocab = get_loader(train_df, vocab = None, max_sent_len = self.max_sent_len)\n",
    "      self.dev_loader,self.dev_dataset,_ = get_loader(val_df, vocab = vocab, max_sent_len = self.max_sent_len)\n",
    "      \n",
    "      self.PAD_IDX = self.vocab.stoi[\"<PAD>\"]\n",
    "      self.INPUT_DIM = len(self.vocab)\n",
    "      self.EMBEDDING_DIM = self.config['model']['embedding_dim']\n",
    "      self.N_FILTERS = self.config['model']['n_filters']\n",
    "      self.FILTER_SIZES = self.config['model']['filter_sizes']\n",
    "      self.OUTPUT_DIM = self.config['model']['output_dim']\n",
    "      self.DROPOUT = self.config['model']['dropout']\n",
    "      self.checkpoint_path = self.config['model']['checkpoint_path']\n",
    "      \n",
    "      self.learning_rate = self.config['train']['learning_rate']\n",
    "      self.num_epochs = self.config['train']['num_epochs']\n",
    "      print(self.num_epochs)\n",
    "      self.model = CNN(self.INPUT_DIM, self.EMBEDDING_DIM, self.N_FILTERS, self.FILTER_SIZES, self.OUTPUT_DIM, self.DROPOUT, self.PAD_IDX, device = self.device)\n",
    "      self.model.apply(initialize_weights)\n",
    "\n",
    "    def train(self):\n",
    "      optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, betas = (0.99,0.98))\n",
    "\n",
    "    #   scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = int(self.num_epochs * len(self.train_loader) * 0.15), \n",
    "    #                                                      num_training_steps = self.num_epochs * len(self.train_loader) )\n",
    "      scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5)\n",
    "      criterion = nn.CrossEntropyLoss(ignore_index=self.PAD_IDX)\n",
    "\n",
    "      # Tensorboard for nice plot\n",
    "\n",
    "      step = 0\n",
    "      best_val_loss = 999\n",
    "      lrs = []\n",
    "      train_loss = []\n",
    "      val_loss = []\n",
    "\n",
    "      start_time = datetime.datetime.now()\n",
    "      for epoch in range(self.num_epochs):\n",
    "        print(\"**************************************************************************    Epoch number {}    **************************************************************************\".format(epoch + 1))\n",
    "        losses = []\n",
    "        for batch_idx, (src, tgt) in enumerate(tqdm(self.train_loader, position=0, leave=True)):\n",
    "          step += 1\n",
    "          loss, lr = training_step(self.model,optimizer,src,tgt,criterion)\n",
    "          lrs.append(lr)\n",
    "          losses.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "          if (step == 1) or step % 50 == 0 or step == len(self.train_loader) * self.num_epochs:\n",
    "            eval_loss = validate(self.model,self.dev_loader, criterion, scheduler)\n",
    "\n",
    "            train_loss.append(sum(losses) / len(losses))\n",
    "            val_loss.append(eval_loss)\n",
    "            current_time =  datetime.datetime.now()\n",
    "            time_taken = current_time - start_time\n",
    "            print(\"Current step: {0}, epoch: {1}\".format(step,epoch + 1), end = \"    \")\n",
    "            print(\"Training loss: \", sum(losses) / len(losses), end = \"    \")\n",
    "            print(\"Evaluation loss: \", eval_loss, end = \"    \" )\n",
    "            print(\"Time elapsed: \", time_taken, end = \"    \")\n",
    "#             writer_train.add_scalar('Loss', sum(losses) / len(losses) , step)\n",
    "#             writer_dev.add_scalar('Loss', eval_loss, step)\n",
    "\n",
    "            if eval_loss < best_val_loss:\n",
    "              print(\"(Best weights saved!) \")\n",
    "              best_val_loss = eval_loss\n",
    "              checkpoint = {\n",
    "                \"state_dict\" : self.model.state_dict(),\n",
    "                \"optimizer\" : optimizer.state_dict(),\n",
    "                \"scheduler\" : scheduler.state_dict()}\n",
    "\n",
    "              # Save the checkpoint with the lowest loss\n",
    "              save_checkpoint(checkpoint , self.checkpoint_path) \n",
    "\n",
    "\n",
    "            else:\n",
    "              print()\n",
    "      \n",
    "    def predict(self,sentences):\n",
    "        load_checkpoint(self.checkpoint_path, self.model)\n",
    "        x = []\n",
    "        for sent in sentences:\n",
    "#             print(sent)\n",
    "            sent_numericalized = [self.vocab.stoi[\"<SOS>\"]]\n",
    "            sent_numericalized += self.vocab.numericalize(sent)\n",
    "\n",
    "            if len(sent_numericalized) > self.max_sent_len:\n",
    "                sent_numericalized = sent_numericalized[:self.max_sent_len]\n",
    "\n",
    "            sent_tensor = np.full(self.max_sent_len, self.vocab.stoi[\"<PAD>\"])\n",
    "            sent_tensor[:len(sent_numericalized)] = sent_numericalized\n",
    "            sent_tensor = torch.Tensor(sent_tensor).long()\n",
    "            x.append(sent_tensor)\n",
    "#             print(sent_tensor.shape)\n",
    "        x = torch.stack(x, dim = 0)\n",
    "        x = x.to(self.device)\n",
    "        output  = self.model(x)\n",
    "        classification = torch.argmax(output, dim = 1)\n",
    "        return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cae65f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'embedding_dim': 128, 'n_filters': 50, 'filter_sizes': [3, 4], 'output_dim': 3, 'dropout': 0.5, 'max_sent_len': 120, 'checkpoint_path': 'model_checkpoint/cnn.pth.tar'}, 'train': {'learning_rate': 0.0005, 'num_epochs': 10}}\n",
      "10\n",
      "**************************************************************************    Epoch number 1    **************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f81c32308b46178049e2e1f6fc4ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step: 1, epoch: 1    Training loss:  1.0683135986328125    Evaluation loss:  0.7915439772605896    Time elapsed:  0:00:00.187512    (Best weights saved!) \n",
      "Current step: 50, epoch: 1    Training loss:  0.7739304971694946    Evaluation loss:  0.6346079897880554    Time elapsed:  0:00:00.793894    (Best weights saved!) \n",
      "Current step: 100, epoch: 1    Training loss:  0.7019010418653489    Evaluation loss:  0.6341163039207458    Time elapsed:  0:00:01.386289    (Best weights saved!) \n",
      "Current step: 150, epoch: 1    Training loss:  0.6782874488830566    Evaluation loss:  0.6334522080421447    Time elapsed:  0:00:01.980704    (Best weights saved!) \n",
      "**************************************************************************    Epoch number 2    **************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee0a8474aca46c9a67435c4359e6c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step: 200, epoch: 2    Training loss:  0.6411525862557548    Evaluation loss:  0.6334294843673706    Time elapsed:  0:00:02.611987    (Best weights saved!) \n",
      "Current step: 250, epoch: 2    Training loss:  0.6228831653863611    Evaluation loss:  0.6317338633537293    Time elapsed:  0:00:03.236311    (Best weights saved!) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14108/3162018220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcnnClassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_Classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcnnClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# tokenizeTranslator = TransformerTranslator(tk_config, device, input_type = 'tokenization')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# print(len(tokenizeTranslator.vi_vocab), len(tokenizeTranslator.en_vocab))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14108/2098923555.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m           \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m           \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m           \u001b[0mlrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m           \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14108/3118426538.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(model, optimizer, src, tgt, criterion)\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m   \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mclip_coef_clamped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef_clamped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('config/cnn.yml') as f:\n",
    "    config = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "print(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cnnClassifier = CNN_Classifier(config, device)\n",
    "cnnClassifier.train()\n",
    "# tokenizeTranslator = TransformerTranslator(tk_config, device, input_type = 'tokenization')\n",
    "# print(len(tokenizeTranslator.vi_vocab), len(tokenizeTranslator.en_vocab))\n",
    "# # bpeTranslator.inference(\"My family was not poor , and myself , I had never experienced hunger since 2002.\", tensor_input = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "25cd1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification = cnnClassifier.predict(test_df['sentences'])\n",
    "\n",
    "classification[100:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1458c26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giáo_trình chưa cụ_thể</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giảng buồn_ngủ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>giáo_viên vui_tính tận_tâm</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giảng_viên nên giao bài_tập nhiều hơn chia nhó...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giảng_viên cần giảng bài chi_tiết hơn đi sâu h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>hướng_dẫn lab mơ_hồ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>thầy cho chúng em những bài_tập mang tính thực...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>thầy không dạy nhiều chủ_yếu cho sinh_viên tự ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>em muốn đổi tên môn_học vì tên môn là lập_trìn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>thầy vừa dạy vừa chat hoặc gọi điện_thoại thườ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentences  sentiments\n",
       "0                                giáo_trình chưa cụ_thể           0\n",
       "1                                        giảng buồn_ngủ           0\n",
       "2                            giáo_viên vui_tính tận_tâm           2\n",
       "3     giảng_viên nên giao bài_tập nhiều hơn chia nhó...           0\n",
       "4     giảng_viên cần giảng bài chi_tiết hơn đi sâu h...           0\n",
       "...                                                 ...         ...\n",
       "1578                                hướng_dẫn lab mơ_hồ           0\n",
       "1579  thầy cho chúng em những bài_tập mang tính thực...           2\n",
       "1580  thầy không dạy nhiều chủ_yếu cho sinh_viên tự ...           0\n",
       "1581  em muốn đổi tên môn_học vì tên môn là lập_trìn...           0\n",
       "1582  thầy vừa dạy vừa chat hoặc gọi điện_thoại thườ...           0\n",
       "\n",
       "[1583 rows x 2 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "model = cnnClassifier.model\n",
    "load_checkpoint(model, config['model']['checkpoint_path'])\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "pred_total = torch.tensor([])\n",
    "labels_total = torch.tensor([])\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = model(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output, labels)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    #convert model output to predicted labels\n",
    "    out = output.tolist()\n",
    "    out = np.array(out)\n",
    "    pred = torch.tensor(out.argmax(axis=1))\n",
    "    pred_total = torch.cat((pred_total, pred))\n",
    "    labels_total = torch.cat((labels_total, labels))\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "pred = pred.tolist()\n",
    "labels = labels.tolist()\n",
    "\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(labels_total, pred_total, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
